# è¡¥å……MiniMindä¸­çš„ä¸€äº›ç»†èŠ‚
## Yarn
### ROPE
https://zhuanlan.zhihu.com/p/667864459

rotate_half()ï¼š
![Alt text](image.png)
![Alt text](image-1.png)



## MOE

##

# ã€é‡è¦ã€‘ä¸€äº›æœ‰è¶£çš„æ€è€ƒ

* ä»€ä¹ˆå«åš**L**arge **L**anguage **M**odel (LLM)ï¼Ÿ
* ä»€ä¹ˆå«åšå¤šæ¨¡æ€æ¨¡å‹ï¼Ÿ

[è¿™ç¯‡æ–‡ç« ](https://www.jiqizhixin.com/articles/2024-09-15-3)å®Œç¾å»åˆæœ¬äººçš„æƒ³æ³•ï¼š
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åå­—è™½ç„¶å¸¦æœ‰è¯­è¨€äºŒå­—ï¼Œä½†å®ƒä»¬å…¶å®ä¸è¯­è¨€å…³ç³»ä¸å¤§ï¼Œè¿™åªæ˜¯å†å²é—®é¢˜ï¼Œæ›´ç¡®åˆ‡çš„åå­—åº”è¯¥æ˜¯è‡ªå›å½’ Transformer
æˆ–è€…å…¶ä»–ã€‚LLM æ›´å¤šæ˜¯ä¸€ç§ç»Ÿè®¡å»ºæ¨¡çš„é€šç”¨æŠ€æœ¯ï¼Œå®ƒä»¬ä¸»è¦é€šè¿‡è‡ªå›å½’ Transformer æ¥æ¨¡æ‹Ÿ token æµï¼Œè€Œè¿™äº› token
å¯ä»¥ä»£è¡¨æ–‡æœ¬ã€å›¾ç‰‡ã€éŸ³é¢‘ã€åŠ¨ä½œé€‰æ‹©ã€ç”šè‡³æ˜¯åˆ†å­ç­‰ä»»ä½•ä¸œè¥¿ã€‚
å› æ­¤ï¼Œåªè¦èƒ½å°†é—®é¢˜è½¬åŒ–ä¸ºæ¨¡æ‹Ÿä¸€ç³»åˆ—ç¦»æ•£ token çš„æµç¨‹ï¼Œç†è®ºä¸Šéƒ½å¯ä»¥åº”ç”¨ LLM æ¥è§£å†³ã€‚
å®é™…ä¸Šï¼Œéšç€å¤§å‹è¯­è¨€æ¨¡å‹æŠ€æœ¯æ ˆçš„æ—¥ç›Šæˆç†Ÿï¼Œæˆ‘ä»¬å¯èƒ½ä¼šçœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„é—®é¢˜è¢«çº³å…¥è¿™ç§å»ºæ¨¡èŒƒå¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé—®é¢˜å›ºå®šåœ¨ä½¿ç”¨ LLM
è¿›è¡Œã€ä¸‹ä¸€ä¸ª token çš„é¢„æµ‹ã€ï¼Œåªæ˜¯æ¯ä¸ªé¢†åŸŸä¸­ token çš„ç”¨é€”å’Œå«ä¹‰æœ‰æ‰€ä¸åŒã€‚

[ZJU-LiXiè€å¸ˆ](https://person.zju.edu.cn/xilics#694283)åŒæ ·è°ˆåŠè¿‡ç±»ä¼¼è§‚ç‚¹ï¼ˆåŸè¯å¤§æ„å¦‚ä¸‹ï¼‰ï¼š
æ–‡æœ¬ã€è§†é¢‘ã€è¯­éŸ³ã€åŠ¨ä½œç­‰åœ¨äººç±»çœ‹æ¥å±äºã€Œå¤šæ¨¡æ€ã€ä¿¡å·ï¼Œä½†æ‰€è°“çš„ã€Œæ¨¡æ€ã€å…¶å®åªæ˜¯äººç±»åœ¨ä¿¡æ¯å­˜å‚¨æ–¹å¼ä¸Šçš„ä¸€ç§åˆ†ç±»æ¦‚å¿µã€‚
å°±åƒ`.txt`å’Œ`.png`æ–‡ä»¶ï¼Œè™½ç„¶åœ¨è§†è§‰å‘ˆç°å’Œé«˜çº§è¡¨ç°å½¢å¼ä¸Šæœ‰æ‰€ä¸åŒï¼Œä½†å®ƒä»¬æœ¬è´¨ä¸Šå¹¶æ²¡æœ‰æ ¹æœ¬åŒºåˆ«ã€‚
ä¹‹æ‰€ä»¥å‡ºç°ã€Œå¤šæ¨¡æ€ã€è¿™ä¸ªæ¦‚å¿µï¼Œä»…ä»…æ˜¯å› ä¸ºäººç±»åœ¨ä¸åŒçš„æ„ŸçŸ¥å±‚é¢ä¸Šå¯¹è¿™äº›ä¿¡å·çš„åˆ†ç±»éœ€æ±‚ã€‚
ç„¶è€Œï¼Œå¯¹äºæœºå™¨æ¥è¯´ï¼Œæ— è®ºä¿¡å·æ¥è‡ªä½•ç§ã€Œæ¨¡æ€ã€ï¼Œæœ€ç»ˆå®ƒä»¬éƒ½åªæ˜¯ä»¥ä¸€ä¸²äºŒè¿›åˆ¶çš„ã€Œå•æ¨¡æ€ã€æ•°å­—åºåˆ—æ¥å‘ˆç°ã€‚
æœºå™¨å¹¶ä¸ä¼šåŒºåˆ†è¿™äº›ä¿¡å·çš„æ¨¡æ€æ¥æºï¼Œè€Œåªæ˜¯å¤„ç†å’Œåˆ†æè¿™äº›åºåˆ—èƒŒåæ‰€æ‰¿è½½çš„ä¿¡æ¯å†…å®¹ã€‚

ä¸ªäººè®¤ä¸º**G**enerative **P**retrained **T**ransformer (GPT) æ¯” **L**arge **L**anguage **M**odel (LLM)æ›´ä¸ºè´´åˆ‡ï¼Œ
å› æ­¤æœ¬äººè¡¨è¾¾ä¸Šæ›´ä¹ æƒ¯ç”¨"GPT"å»ä»£è¡¨LLM/VLM/ç±»GPTæ¶æ„çš„ç³»åˆ—æ¨¡å‹ï¼Œè€Œéä¸ºäº†è¹­OpenAIçš„çƒ­åº¦ã€‚

è‡³æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€å¥è¯æ€»ç»“GPTçš„æ‰€ä½œæ‰€ä¸ºï¼š

GPTæ¨¡å‹æ ¹æ®ç°æœ‰tokené¢„æµ‹è¾“å‡ºä¸‹ä¸€ä¸ªä¸‹ä¸‹ä¸€ä¸ªä¸‹ä¸‹ä¸‹ä¸€ä¸ªtoken ...ï¼Œç›´åˆ°æ¨¡å‹è¾“å‡ºç»“æŸç¬¦ï¼›æ­¤å¤„çš„"token"å…¶å®å¹¶ä¸éœ€è¦ä¸€å®šæ˜¯æ–‡æœ¬ï¼

```text
> å¯¹äºLLMæ¨¡å‹ï¼Œå¦‚æœéœ€è¦ç†è§£"å›¾ç‰‡"ï¼Œæˆ‘ä»¬åªè¦æŠŠ"å›¾ç‰‡"ä½œä¸ºå¯¹ä¸€ç§ç‰¹æ®Šçš„ä»æ¥æ²¡è§è¿‡çš„"å¤–å›½è¯­è¨€"ï¼Œé€šè¿‡"å¤–è¯­è¯å…¸"ç¿»è¯‘åå³å¯ä½œä¸ºç‰¹æ®Šçš„è¯­è¨€è¾“å…¥LLM
> å¯¹äºLLMæ¨¡å‹ï¼Œå¦‚æœéœ€è¦ç†è§£"éŸ³é¢‘"ï¼Œæˆ‘ä»¬åªè¦æŠŠ"éŸ³é¢‘"ä½œä¸ºå¯¹ä¸€ç§ç‰¹æ®Šçš„ä»æ¥æ²¡è§è¿‡çš„"å¤–å›½è¯­è¨€"ï¼Œé€šè¿‡"å¤–è¯­è¯å…¸"ç¿»è¯‘åå³å¯ä½œä¸ºç‰¹æ®Šçš„è¯­è¨€è¾“å…¥LLM
> ...
```

# ğŸ“Œ VLM Detail

MiniMind-Vçš„ç»“æ„ä»…å¢åŠ Visual Encoderå’Œç‰¹å¾æŠ•å½±ä¸¤ä¸ªå­æ¨¡å—ï¼Œå¢åŠ æ¨¡æ€æ··åˆåˆ†æ”¯ï¼Œä»¥æ”¯æŒå¤šç§æ¨¡æ€ä¿¡æ¯çš„è¾“å…¥ï¼š
![LLM-structure](./images/VLM-structure.png)
![LLM-structure](./images/VLM-structure-moe.png)




<u>**ä¸ºäº†å¾—åˆ°MiniMind-Vï¼Œæˆ‘ä»¬åªéœ€è¦å®Œæˆè¿™2ä»¶äº‹å³å¯ï¼š**</u>

1. å€ŸåŠ©æ“…é•¿ç¿»è¯‘å›¾ç‰‡çš„ **"å¤–è¯­è¯å…¸"** ï¼ŒæŠŠå›¾ç‰‡ä» **"å¤–å›½è¯­è¨€"** ç¿»è¯‘ä¸ºæ¨¡å‹ä¾¿äºç†è§£çš„ **"LLMè¯­è¨€"**
2. è®­ç»ƒå¾®è°ƒLLMï¼Œä½¿å…¶å’Œ **"å¤–è¯­è¯å…¸"** åº¦è¿‡ç£¨åˆæœŸï¼Œä»è€Œæ›´å¥½çš„ç†è§£å›¾ç‰‡

"å¤–è¯­è¯å…¸" ç§°ä¹‹ä¸ºVisual Encoderæ¨¡å‹ã€‚
å’ŒLlaVAã€Qwen-VLç­‰è§†è§‰è¯­è¨€æ¨¡å‹ç±»ä¼¼ï¼ŒMiniMind-VåŒæ ·é€‰ç”¨å¼€æºClipç³»åˆ—æ¨¡å‹ä½œä¸ºVisual Encoderã€‚
å…·ä½“ä½¿ç”¨[clip-vit-base-patch16](https://huggingface.co/openai/clip-vit-base-patch16)ï¼Œ
ä¸€ç§åŸºäº ViT-B/16 æ¶æ„çš„ç»å…¸Visual Encoderç”¨äºæè¿°å›¾åƒæ–‡æœ¬ä¿¡æ¯ã€‚
è¾“å…¥çš„å›¾åƒå°ºå¯¸ä¸º224x224ï¼Œå› ä¸ºåˆ’åˆ†çš„Patchæ˜¯16Ã—16ï¼Œæ‰€ä»¥ä¼šäº§ç”Ÿ14*14=196ä¸ªtokenä½œä¸ºencoderç¼–ç å±‚çš„è¾“å…¥ï¼Œ
æœ€ç»ˆäº§ç”Ÿ1Ã—768ç»´çš„åµŒå…¥å‘é‡ç”¨äºå’Œæ–‡æœ¬å¯¹è®¡ç®—è¯¯å·®ã€‚
æˆ‘ä»¬å¹¶ä¸éœ€è¦æœ€ç»ˆåµŒå…¥è¡¨ç¤ºï¼Œå› æ­¤åªå–encoderå±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯VITæ ¸å¿ƒä¸»å¹²çš„è¾“å‡ºç‰¹å¾å³å¯ã€‚
å®ƒæ‹¿åˆ°å‰ä¸€å±‚ç»´åº¦196Ã—768å¤§å°çš„ç‰¹å¾ï¼Œæˆ‘ä»¬æŠŠå®ƒä½œä¸º196ä¸ªvisual tokenè¾“å…¥MiniMind-Vã€‚
ä¸LLMçš„ç»“åˆåœ¨è·å–å›¾åƒencoderç‰¹å¾åï¼Œä¸€æ–¹é¢éœ€è¦æŠŠ768ç»´åº¦çš„visual tokenå¯¹é½åˆ°LLMçš„æ–‡æœ¬tokenï¼Œ
å¦ä¸€æ–¹é¢ï¼Œè¦å°†å›¾åƒç‰¹å¾æ˜ å°„åˆ°ä¸æ–‡æœ¬embeddingç›¸åŒçš„ç©ºé—´ï¼Œå³æ–‡æœ¬tokenå’ŒåŸç”Ÿçš„è§†è§‰tokenéœ€è¦ç£¨åˆå¹¶ä¸èƒ½ç›´æ¥åœ°ä¸€è§†åŒä»ï¼Œ
å¯ä»¥ç§°ä¹‹ä¸ºè·¨æ¨¡æ€çš„ç‰¹å¾å¯¹é½ã€‚
[LlaVA-1](https://arxiv.org/pdf/2304.08485)ä½¿ç”¨ç®€å•çš„æ— åçº¿æ€§å˜æ¢å®Œæˆäº†è¿™ä¸€æ“ä½œï¼Œæ•ˆæœå¾ˆä¸é”™ï¼ŒMiniMind-VåŒæ ·å¦‚æ­¤ã€‚

![llava-structure](./images/llava-structure.png)

è‡³æ­¤ï¼ŒMiniMind-Vçš„å†…éƒ¨ç»“æ„å˜åŒ–å·²ç»å‘ˆç°å®Œæ¯•ã€‚




# è¾“å…¥è¾“å‡ºçš„å˜åŒ–

ä¸‹é¢ï¼Œæˆ‘ä»¬ç®€å•è®¨è®ºMiniMind-Vçš„å¤–éƒ¨è¾“å…¥è¾“å‡ºçš„å˜åŒ–ã€‚

VLMçš„è¾“å…¥ä¾ç„¶æ˜¯ä¸€æ®µæ–‡æœ¬ï¼Œå…¶ä¸­åŒ…å«ç‰¹æ®Šçš„`<image>`å ä½ç¬¦ã€‚
åœ¨è®¡ç®—æ–‡æœ¬åµŒå…¥åï¼Œå¯ä»¥å°†å›¾åƒç¼–ç å™¨ç”Ÿæˆçš„å‘é‡æŠ•å½±åˆ°è¯¥å ä½ç¬¦å¯¹åº”çš„åµŒå…¥éƒ¨åˆ†ï¼Œæ›¿æ¢æ‰åŸå…ˆçš„å ä½ç¬¦embeddingã€‚
ä¾‹å¦‚ï¼š

```text
<image>\nè¿™ä¸ªå›¾åƒä¸­æœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿ
```

åœ¨`minimind-v`ä¸­ï¼Œä½¿ç”¨196ä¸ªå­—ç¬¦ç»„æˆçš„ `@@@...@@@`
å ä½ç¬¦ä»£æ›¿å›¾åƒï¼Œä¹‹æ‰€ä»¥æ˜¯196ä¸ªå­—ç¬¦ï¼Œå‰é¢æœ‰æ‰€æåŠï¼š
ä»»ä½•å›¾åƒéƒ½è¢«clipæ¨¡å‹encoderä¸º196Ã—768ç»´çš„tokenï¼Œ
å› æ­¤`minimind-v`çš„promptä¸ºï¼š

```text
@@@......@@@\nè¿™ä¸ªå›¾ç‰‡æè¿°çš„æ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ
```

è®¡ç®—å®Œembeddingå’Œprojectionï¼Œå¹¶å¯¹å›¾åƒéƒ¨åˆ†tokenæ›¿æ¢åæ•´ä¸ªè®¡ç®—è¿‡ç¨‹åˆ°è¾“å‡ºåˆ™å’ŒLLMéƒ¨åˆ†æ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚

![input](./images/minimind-v-input.png)

ä¸€æ¬¡æ€§å¤šå›¾çš„å®ç°æ–¹æ³•å°±æ˜¯é€šè¿‡æ³¨å…¥å¤šä¸ª`<image>`å›¾åƒå ä½ç¬¦è¿›è¡Œå®ç°ï¼Œä¸éœ€è¦ä¿®æ”¹ä»»ä½•æ¡†æ¶ã€‚

<details>
<summary> è§†é¢‘ç†è§£çš„æ‹“å±•æ€è·¯ </summary>

write by [@xinyanghuang7](https://github.com/xinyanghuang7)

å¯¹äºå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œä¸€ä¸ªå¯è¡Œçš„æ€è·¯æ˜¯å‚è€ƒç°æœ‰MiniCPM-V 2.6 è¿›è¡Œè§†é¢‘ç†è§£çš„Pythonç¤ºä¾‹ã€‚
ä¸»è¦æ€æƒ³æ˜¯é€šè¿‡æå–è§†é¢‘å…³é”®å¸§ï¼Œè€Œåè¿›è¡Œå¤šå›¾æ¨ç†ã€‚
å› æ­¤ï¼Œå¦‚æœå¸Œæœ›åœ¨MiniMind-Vä¸­æ·»åŠ è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥åœ¨ç°æœ‰å¤šå›¾è®­ç»ƒçš„åŸºç¡€ä¸Šï¼Œå‚è€ƒæ­¤pythonè„šæœ¬ä¸­å¯¹äºå…³é”®å¸§çš„æå–æ–¹æ³•ï¼Œè€ŒååŠ å¤§è®­ç»ƒæ–‡ä»¶ä¸­æ”¯æŒå›¾ç‰‡çš„æ•°é‡ã€‚
æ‰€æ”¯æŒçš„MAX_NUM_FRAMESè¶Šå¤šï¼Œæ‰€æ¶ˆè€—çš„æ˜¾å­˜è¶Šå¤§ã€‚

```text
import torch
from PIL import Image
from transformers import AutoModel, AutoTokenizer
from decord import VideoReader, cpu  # pip install decord

model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2_6', trust_remote_code=True,
                                  attn_implementation='sdpa',
                                  torch_dtype=torch.bfloat16)  # sdpa or flash_attention_2, no eager
model = model.eval().cuda()
tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2_6', trust_remote_code=True)

MAX_NUM_FRAMES = 64  # if cuda OOM set a smaller number


def encode_video(video_path):
    def uniform_sample(l, n):
        gap = len(l) / n
        idxs = [int(i * gap + gap / 2) for i in range(n)]
        return [l[i] for i in idxs]

    vr = VideoReader(video_path, ctx=cpu(0))
    sample_fps = round(vr.get_avg_fps() / 1)  # FPS
    frame_idx = [i for i in range(0, len(vr), sample_fps)]
    if len(frame_idx) > MAX_NUM_FRAMES:
        frame_idx = uniform_sample(frame_idx, MAX_NUM_FRAMES)
    frames = vr.get_batch(frame_idx).asnumpy()
    frames = [Image.fromarray(v.astype('uint8')) for v in frames]
    print('num frames:', len(frames))
    return frames


video_path = "video_test.mp4"
frames = encode_video(video_path)
question = "Describe the video"
msgs = [
    {'role': 'user', 'content': frames + [question]},
]

# Set decode params for video
params = {}
params["use_image_id"] = False
params["max_slice_nums"] = 2  # å¦‚æœcuda OOMä¸”è§†é¢‘åˆ†è¾¨ç‡å¤§äº448*448å¯è®¾ä¸º1

answer = model.chat(
    image=None,
    msgs=msgs,
    tokenizer=tokenizer,
    **params
)
print(answer)
```

</details>

è‡³æ­¤ï¼Œ`MiniMind-V`çš„æ‰€æœ‰ç»†èŠ‚å·²ç»å‘ˆç°å®Œæ¯•ã€‚
`MiniMind-V`çš„æ¨¡å‹å­ç±»å®Œå…¨ç»§æ‰¿è‡ª`MiniMind`ï¼Œ
ä»…åŸºäºåè€…åš**æœ€å°**å˜æ›´è€Œäº§ç”Ÿï¼Œ
å…¶æ ¸å¿ƒç®—æ³•æ”¹åŠ¨`< 50è¡Œ`ï¼Œè¿ç§»éš¾åº¦æä½ã€‚
å› æ­¤å¯èƒ½å’Œ`LlAVA`ç­‰æ¨¡å‹ç»†èŠ‚å¯èƒ½å­˜åœ¨åŒºåˆ«ï¼Œä½†æ€è·¯å®Œå…¨ç»Ÿä¸€ã€‚

# ğŸ“Œ Experiment

## â…  æ•°æ®é›†

æ¥æºï¼š[Chinese-LLaVA-Vision](https://huggingface.co/datasets/LinkSoul/Chinese-LLaVA-Vision-Instructions)
åŒ…å«çº¦57ä¸‡å¼ é¢„è®­ç»ƒå›¾åƒï¼Œæ¥è‡ªCC-3Må’ŒCOCO 2014ï¼›
[llava-en-zh-300k](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)
åŒ…å«300kæ¡æŒ‡ä»¤å¾®è°ƒæ•°æ®å’Œ15ä¸‡å¼ å›¾åƒã€‚
é—®ç­”å†…å®¹ç»è¿‡ç¿»è¯‘ï¼Œ
å¯¹ä¸­æ–‡æ”¯æŒæ›´å‹å¥½ï¼Œè¿›ä¸€æ­¥ç»è¿‡æ•´ç†å¹¶`resize`ã€‚

(pretrain_vlm_data.jsonl) é¢„è®­ç»ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  "conversations": [
    {
      "role": "user",
      "content": "æä¾›ç»™å®šå›¾åƒçš„ç®€è¦æè¿°ã€‚\n<image>"
    },
    {
      "role": "assistant",
      "content": "æ©„æ¦„æ²¹æ˜¯è‡ªç”±ä½¿ç”¨çš„å¥åº·æˆåˆ†ã€‚"
    }
  ],
  "image": "GCC_train_002582585.jpg"
}
```

(sft_vlm_data.jsonl) å•å›¾æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  "conversations": [
    {
      "role": "user",
      "content": "é—¹é’Ÿçš„ä½ç½®å¯¹ç¡çœ è´¨é‡æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ<image>"
    },
    {
      "role": "assistant",
      "content": "æŠŠæ•°å­—é—¹é’Ÿæ”¾åœ¨åºŠå¤´æŸœ..."
    }
  ],
  "image": "train-00000-of-00001_image_0_0.jpg"
}
```

(sft_vlm_data_multi.jsonl) å¤šå›¾æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ ¼å¼ï¼š

```json lines
{
  "conversations": [
    {
      "role": "user",
      "content": "context: Source Image: <image> Target Image: <image> Instruction: What is the correct image edit instruction that can transfrom the source image to target image?<image>"
    },
    {
      "role": "assistant",
      "content": "take the people out of the back in the photo. Remove the two people behind the woman in the white dress and the man in the blue suit. remove people behind the couple in the centre"
    }
  ],
  "image": "0.jpg, 1.jpg"
}
```

